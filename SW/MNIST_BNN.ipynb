{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ionhedes/CA2020/blob/master/SW/MNIST_BNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddhSdu2zlDXj"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn6UslIJlIOj"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs_p3wjvlJPr",
        "outputId": "3f99783e-9664-4e4f-fd71-e1f5170aed4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: larq in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from larq) (1.25.2)\n",
            "Requirement already satisfied: terminaltables>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from larq) (3.1.10)\n",
            "Requirement already satisfied: packaging>=19.2 in /usr/local/lib/python3.10/dist-packages (from larq) (24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install larq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNlvlsDYlZN7",
        "outputId": "601676a8-07cd-45b2-c52f-3db10be41c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netron in /usr/local/lib/python3.10/dist-packages (7.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install netron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu9jpxcxldAy"
      },
      "source": [
        "## Settings & imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LCfiAHsgVgQ8"
      },
      "outputs": [],
      "source": [
        "#===== Reproducibility Settings (Before TensorFlow Import) =====#\n",
        "import os\n",
        "#*IMPORANT*: Have to do this line *before* importing tensorflow\n",
        "os.environ['PYTHONHASHSEED']=str(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IN2mpid7OOsk"
      },
      "outputs": [],
      "source": [
        "from math import frexp\n",
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "import netron\n",
        "from google.colab import output, drive\n",
        "from typing import Dict, List\n",
        "from json import dump, load\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z5FGcOGMVukd"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkMmjR20lScp"
      },
      "source": [
        "## Storage and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2Wopvq6-dOvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d4be99-3ab0-495b-f4a2-26cb092accc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9FcvsjPxdQHS"
      },
      "outputs": [],
      "source": [
        "workdir = './drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uo0boAG1gmW"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u1_lJ50V1h_W"
      },
      "outputs": [],
      "source": [
        "DEBUG = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "er8XG0JQ2LXA"
      },
      "outputs": [],
      "source": [
        "def _dbg(msg: str) -> None:\n",
        "    if 'DEBUG' in globals() and DEBUG == True:\n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset download"
      ],
      "metadata": {
        "id": "JgQYMSip39ZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NH9WeW0dOX8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a22096-9c32-4c73-b94b-01075f33e3c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = train_x.reshape((60000, 28, 28, 1))\n",
        "test_x = test_x.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Center pixel values around 0. They will be quantized to -1, 1 by the network\n",
        "train_x, test_x = train_x - 127.5, test_x - 127.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuXmlSSvTsor"
      },
      "source": [
        "# Model architecture and instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F2QLlxUyHDPq"
      },
      "outputs": [],
      "source": [
        "def create_lenet() -> tf.keras.Model:\n",
        "    # All quantized layers use ste_sign for input and weights, and the weights are clipped between -1 and 1\n",
        "    kwargs = dict(use_bias=False,\n",
        "                input_quantizer=\"ste_sign\",\n",
        "                kernel_quantizer=\"ste_sign\",\n",
        "                kernel_constraint=\"weight_clip\")\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # 5x5 first layer much better (~95 to ~98) and slightly cheaper (2.7 to 2.6). 16 channel first layer much cheaper (1.1 to 0.6), and slightly worse (~98 to ~97), 8 channel is 0.6 to 0.3 and ~97 to ~94\n",
        "    model.add(lq.layers.QuantConv2D(8, (5, 5), input_shape=(28, 28, 1), **kwargs))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((3, 3))) # With 5x5 kernel, 3x3 max pooling is only slightly lower than 2x2 (~98 to ~97), and much cheaper (2.6 to 1.1)\n",
        "    model.add(tf.keras.layers.BatchNormalization(scale=False, center=False)) # center=False lowers accuracy from ~96 to ~95, LayerNorm seems better but also more complex\n",
        "\n",
        "    # Given above 8, 64 -> 32 is 0.3 to 0.2 and -0.5\n",
        "    model.add(lq.layers.QuantConv2D(32, (3, 3), **kwargs))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "    model.add(tf.keras.layers.BatchNormalization(scale=False, center=False))\n",
        "\n",
        "    # Optional layer for ~+0\n",
        "    # model.add(lq.layers.QuantConv2D(64, (3, 3), **kwargs)) # A third conv layer is cheaper (2.7M MACs) and better (~95) than a 256 dense layer (2.8M MACs and ~94)\n",
        "    # model.add(tf.keras.layers.BatchNormalization(scale=False, center=False))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(lq.layers.QuantDense(64, **kwargs))\n",
        "    model.add(tf.keras.layers.BatchNormalization(scale=False, center=False))\n",
        "    model.add(lq.layers.QuantDense(10, **kwargs))\n",
        "    model.add(tf.keras.layers.BatchNormalization(scale=False,  center=False))\n",
        "    #model.add(tf.keras.layers.Activation(lq.quantizers.SteSign()))\n",
        "    model.add(tf.keras.layers.Activation(\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Bd9eQgKU1LH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a585c9db-51d7-4116-9135-e533da9e1355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+sequential stats----------------------------------------------------------------------------+\n",
            "| Layer                  Input prec.          Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs |\n",
            "|                              (bit)                       x 1       x 1    (kB)             |\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "| quant_conv2d                     1  (-1, 24, 24, 8)      200         0    0.02      115200 |\n",
            "| max_pooling2d                    -    (-1, 8, 8, 8)        0         0       0           0 |\n",
            "| batch_normalization              -    (-1, 8, 8, 8)        0        16    0.06           0 |\n",
            "| quant_conv2d_1                   1   (-1, 6, 6, 32)     2304         0    0.28       82944 |\n",
            "| max_pooling2d_1                  -   (-1, 3, 3, 32)        0         0       0           0 |\n",
            "| batch_normalization_1            -   (-1, 3, 3, 32)        0        64    0.25           0 |\n",
            "| flatten                          -        (-1, 288)        0         0       0           0 |\n",
            "| quant_dense                      1         (-1, 64)    18432         0    2.25       18432 |\n",
            "| batch_normalization_2            -         (-1, 64)        0       128    0.50           0 |\n",
            "| quant_dense_1                    1         (-1, 10)      640         0    0.08         640 |\n",
            "| batch_normalization_3            -         (-1, 10)        0        20    0.08           0 |\n",
            "| activation                       -         (-1, 10)        0         0       0           ? |\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "| Total                                                  21576       228    3.52      217216 |\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "+sequential summary---------------------------+\n",
            "| Total params                      21.8 k    |\n",
            "| Trainable params                  21.6 k    |\n",
            "| Non-trainable params              228       |\n",
            "| Model size                        3.52 KiB  |\n",
            "| Model size (8-bit FP weights)     2.86 KiB  |\n",
            "| Float-32 Equivalent               85.17 KiB |\n",
            "| Compression Ratio of Memory       0.04      |\n",
            "| Number of MACs                    217 k     |\n",
            "| Ratio of MACs that are binarized  1.0000    |\n",
            "+---------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "model = create_lenet()\n",
        "lq.models.summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "***Do not run if you're importing the weights from a previous run!***"
      ],
      "metadata": {
        "id": "sK7VP9f93qTy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jddmxhw41SM2"
      },
      "outputs": [],
      "source": [
        "model.fit(train_x, train_y, batch_size=64, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSCPaHQeTvjC"
      },
      "source": [
        "# Integer quantization of non-binary weights\n",
        "***Don't run the weight import if you run this!***\n",
        "\n",
        "**What is the objective?**\n",
        "Get a Keras model with integer and binary weights only.\n",
        "\n",
        "**What strategies have I thought of?**\n",
        "1. naively truncate the weights of the current model\n",
        "2. apply [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant) using TFLite\n",
        "\n",
        "**Which strategy should we use?**\n",
        "\n",
        "Naively truncating the weights to integers is easier and results in the same evaluation accuracy (in software). I haven't managed to make the 2nd method work yet. Therefore, I propose we use it (timestamp for future reference: **27.05, 3:59 PM**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPHwdLk7MjvW"
      },
      "source": [
        "## Naively truncating the weights\n",
        "\n",
        "**Steps:**\n",
        "1. Copy the model without truncating the weights. Evaluate. *Why?* To make sure the same accuracy is achievable by naively copying weights from one model to another.\n",
        "2. Copy the model and truncate the weights. Evaluate.\n",
        "3. Copy the model (with `larq`'s `quantized_scope` set to `True`) and truncate the rest of the weights. Evaluate. *Why isn't step 2 enough?* Copying weights might not preserve `larq` quantization. The `larq` execution model is still unclear to me.\n",
        "\n",
        "**Conclusion:**\n",
        "- copying weights from one model to another is fine in general.\n",
        "- truncating weights without ensuring `larq`'s quantization scope destroys performance.\n",
        "- truncating weights while ensuring `larq`'s quantization scope preserves performance. <font color=\"lightgreen\">We can use this strategy to obtain integer weights!</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmNjEJ7aJol4"
      },
      "outputs": [],
      "source": [
        "# copy & evaluate without truncation\n",
        "copy_model = create_lenet()\n",
        "for copy_layer, layer in zip(copy_model.layers, model.layers):\n",
        "    copy_layer.set_weights(layer.get_weights())\n",
        "\n",
        "copy_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "copy_model.evaluate(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzK2P431NysM"
      },
      "outputs": [],
      "source": [
        "# copy & evaluate with truncation\n",
        "int_model = create_lenet()\n",
        "for int_layer, layer in zip(int_model.layers, model.layers):\n",
        "    trunc_weights = [np.trunc(v) for v in layer.get_weights()]\n",
        "    int_layer.set_weights(trunc_weights)\n",
        "\n",
        "int_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "int_model.evaluate(test_x, test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ch1FDIoTbGO"
      },
      "outputs": [],
      "source": [
        "# copy & evaluate with truncation & larq quantized scope\n",
        "lq_int_model = create_lenet()\n",
        "with lq.context.quantized_scope(True):\n",
        "    for lq_int_layer, layer in zip(lq_int_model.layers, model.layers):\n",
        "        trunc_weights = [np.ceil(v) for v in layer.get_weights()]  # better perf than .trunc\n",
        "        lq_int_layer.set_weights(trunc_weights)\n",
        "\n",
        "lq_int_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "lq_int_model.evaluate(test_x, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4_Sx1mPMnTV"
      },
      "source": [
        "## ~Applying post-training quantization using TFLite~\n",
        "\n",
        "**Steps:**\n",
        "1. train model normally (see previous section)\n",
        "2. quantize to integer weights using TFLite\n",
        "3. inspect and evaluate TFLite model\n",
        "4. extract the model weights and move them to a new Keras model (this step might be necessary to check if TFLite introduces bullshit optimizations)\n",
        "5. evaluate the new Keras model. Are all the weights integers? Is the accuracy comparable to that of the initial model?\n",
        "\n",
        "**Why not just use the TFLite model?**\n",
        "Because it might include additional implicit optimizations that we're not aware of/can't easily reproduce in hardware.\n",
        "\n",
        "**Conclusion:**\n",
        "- TFLite introduces additional quantization operations that might be hard to replicate in hardware.\n",
        "- Stopped at step 4. Until proven inappropriate, the **naive weight integer truncation** method is easier, and the go-to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4LzrrGRT0xr"
      },
      "source": [
        "### Quantize\n",
        "\n",
        "See [this](https://www.tensorflow.org/lite/performance/post_training_quantization), and [this](https://www.tensorflow.org/lite/performance/post_training_integer_quant) for possible integer quantization strategies.\n",
        "\n",
        "Trying to apply **full-integer quantization** (all intermediate operations use integers, no falling back to float operations) to best simulate the hardware environment we're building\n",
        "\n",
        "See [this](https://www.tensorflow.org/lite/guide/signatures) to learn what **signatures** are (used for creating representative datasets). A good explanation on why they're needed in this context can be found [here](https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_float_fallback_quantization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7roN5xqXZc4"
      },
      "outputs": [],
      "source": [
        "REPR_DATASET_SIZE = 100\n",
        "\n",
        "def representative_data_gen():\n",
        "    # note: tensor-flavored generators are not encouraged, but I think they're\n",
        "    # enough for our needs\n",
        "    for inp in tf.data.Dataset.from_tensor_slices(train_x).batch(1).take(REPR_DATASET_SIZE):\n",
        "        yield [np.float32(inp)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfn3SvSxT621"
      },
      "outputs": [],
      "source": [
        "# set up converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# convert to tflite unquantized\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# convert to tflite quantized\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # signed 8-bit integer\n",
        "converter.inference_output_type = tf.int8  # signed 8-bit integer\n",
        "tflite_int_quant_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPevWuR9c8wa"
      },
      "outputs": [],
      "source": [
        "# save quantized model\n",
        "tflite_int_quant_model_name = 'tflite_int_quant_model'\n",
        "with open(f'{workdir}/{tflite_int_quant_model_name}.tflite', 'wb') as fp:\n",
        "    fp.write(tflite_int_quant_model)\n",
        "\n",
        "# save non-quantized model as well\n",
        "tflite_model_name = 'tflite_std_model'\n",
        "with open(f'{workdir}/{tflite_model_name}.tflite', 'wb') as fp:\n",
        "    fp.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eQXdwPNZOR1"
      },
      "source": [
        "### Inspect\n",
        "\n",
        "**27.05 12:40 PM**\n",
        "- `larq` might not be playing nicely with tflite (see Netron below) -- weights set to $\\pm127$\n",
        "- the `tflite` quantization seems to be introducing some bullshit in the model; do we need to move that to hardware?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw95dwiHZPl9"
      },
      "outputs": [],
      "source": [
        "# inspect using prints (not really useful)\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_int_quant_model)\n",
        "tensor_details = interpreter.get_tensor_details()\n",
        "for layer_dict in tensor_details:\n",
        "    print(layer_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVFKJXuscUzL"
      },
      "outputs": [],
      "source": [
        "# visualize the quantized model using Netron\n",
        "with output.temporary():\n",
        "    host, port = netron.start(f'{workdir}/{tflite_int_quant_model_name}.tflite')\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQnhZUj-T2ly"
      },
      "source": [
        "### Evaluate\n",
        "\n",
        "**27.05 13:09 PM**\n",
        "- `accuracy_tf_std == accuracy_tfl_std`\n",
        "- `abs(accuracy_tf_std - accuracy_tfl_int_quant) == 0.12%`\n",
        "- not sure if the tested models preserve the `larq` quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdx8sZ8upj63"
      },
      "source": [
        "#### Helper functions\n",
        "Copy-pasted and adjusted from [here](https://www.tensorflow.org/lite/performance/post_training_integer_quant#run_the_tensorflow_lite_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPuF8WSYpln_"
      },
      "outputs": [],
      "source": [
        "# Helper function to run inference on a TFLite model\n",
        "def run_tflite_model(tflite_model, test_images):\n",
        "    # Initialize the interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()[0]\n",
        "    output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "    predictions = np.zeros((len(test_images),), dtype=int)\n",
        "    for i, test_image in enumerate(test_images):\n",
        "\n",
        "        # Check if the input type is quantized, then rescale input data to uint8\n",
        "        if input_details['dtype'] == np.uint8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "        predictions[i] = output.argmax()\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMISwUiNqAS2"
      },
      "outputs": [],
      "source": [
        "# Helper function to evaluate a TFLite model on all images\n",
        "def evaluate_model(tflite_model, test_images, test_labels, model_type):\n",
        "    predictions = run_tflite_model(tflite_model, test_images)\n",
        "\n",
        "    accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
        "\n",
        "    print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
        "          model_type, accuracy, len(test_images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7odb7HQdvT9p"
      },
      "source": [
        "#### Actual evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fwmPXCgqdaV"
      },
      "outputs": [],
      "source": [
        "# evaluate integer quantized model (tflite version)\n",
        "evaluate_model(tflite_int_quant_model, test_x, test_y, model_type='Quantized')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4RKCG8Qtv3v"
      },
      "outputs": [],
      "source": [
        "# evaluate non-quantized model (tflite version)\n",
        "evaluate_model(tflite_model, test_x, test_y, model_type='Float')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBItO63dFy1d"
      },
      "source": [
        "### Create new Keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExRPXkQ9FyXF"
      },
      "outputs": [],
      "source": [
        "# stopped here because I succeeded obtaining an integer-weighted model\n",
        "# using the other method"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m7UfM_4WN6v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight import\n",
        "***Don't run the weight export and weight quantization steps if you run this!***"
      ],
      "metadata": {
        "id": "X7TGHX8jo-yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight import script and execution"
      ],
      "metadata": {
        "id": "R4uBzywTziqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _import_dense_weights(layer,\n",
        "                           weights: List) -> Dict:\n",
        "\n",
        "    if len(weights.keys()) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - weights\\n\"\n",
        "             f\"\\t\\t - biases\")\n",
        "    elif len(weights.keys()) == 1:\n",
        "        # without biases\n",
        "        _dbg(f\"\\t\\t - weights\")\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "    weights_list = [np.array(arr) for arr in weights.values()]\n",
        "    layer.set_weights(weights_list)"
      ],
      "metadata": {
        "id": "okb7EPn_zJAJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _import_bn_weights(layer,\n",
        "                        weights: List) -> Dict:\n",
        "\n",
        "    if len(weights.keys()) == 2:\n",
        "        # no betas, gammas\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - means\\n\"\n",
        "             f\"\\t\\t - variances\")\n",
        "    elif len(weights.keys()) == 4:\n",
        "        # with betas, gammas\n",
        "        _dbg(f\"\\t\\t - means\\n\"\n",
        "             f\"\\t\\t - variances\\n\"\n",
        "             f\"\\t\\t - betas\\n\"\n",
        "             f\"\\t\\t - gammas\")\n",
        "        raise NotImplementedError('Importing weights is not implemented for batch normalization with scaling and centering.')\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "\n",
        "    weights_list = [np.array(arr) for arr in weights.values()]\n",
        "    layer.set_weights(weights_list)"
      ],
      "metadata": {
        "id": "-F9Dp2ctyjkY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _import_conv_weights(layer,\n",
        "                          weights: Dict) -> None:\n",
        "\n",
        "    if len(weights.keys()) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - kernels\\n\"\n",
        "             f\"\\t\\t - biases\")\n",
        "    elif len(weights.keys()) == 1:\n",
        "        # without biases\n",
        "        _dbg(f\"\\t\\t - kernels\")\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "    weights_list = [np.array(arr) for arr in weights.values()]\n",
        "    layer.set_weights(weights_list)"
      ],
      "metadata": {
        "id": "rO42APKav8DD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _dispatch_import_weights_layer_specific(layer,\n",
        "                                            weights: Dict) -> None:\n",
        "    weightless_layers = ['pool', 'flatten', 'activation']\n",
        "\n",
        "    layer_name = layer.get_config()['name']\n",
        "\n",
        "    if 'conv2d' in layer_name:\n",
        "        _dbg(f\"\\t - convolutional layer <{layer_name}>\")\n",
        "        _import_conv_weights(layer, weights)\n",
        "    elif 'batch_normalization' in layer_name:\n",
        "        _dbg(f\"\\t - batch normalization layer <{layer_name}>\")\n",
        "        _import_bn_weights(layer, weights)\n",
        "    elif 'dense' in layer_name:\n",
        "        _dbg(f\"\\t - dense layer <{layer_name}>\")\n",
        "        _import_dense_weights(layer, weights)\n",
        "    elif any([wl in layer_name for wl in weightless_layers]):\n",
        "        # a supported layer that has no weights\n",
        "        _dbg(f\"\\t - ignoring weightless layer <{layer_name}>\")\n",
        "        return dict()\n",
        "    else:\n",
        "        raise ValueError('This layer type is not supported.')"
      ],
      "metadata": {
        "id": "2eznRjWuuAm7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_weights(model: tf.keras.Model,\n",
        "                    file_path: str,\n",
        "                    file_name: str) -> None:\n",
        "    \"\"\"Imports the weights to the model. Make sure the neural network topology\n",
        "    is the same.\n",
        "\n",
        "    Args:\n",
        "    `model` -- neural net model\n",
        "    `quantized` -- set to true if you want to export `larq`-quantized weights\n",
        "    `file_path` -- path to weight file.\n",
        "    `file_name` -- name of the weight file.\n",
        "    \"\"\"\n",
        "\n",
        "    _dbg(f\"Importing weights from {file_path}/{file_name}.json\")\n",
        "\n",
        "    ret = dict()\n",
        "    name_idx_dict = dict()\n",
        "\n",
        "    with open(f'{file_path}{file_name}.json', 'r') as fp:\n",
        "\n",
        "        # load json dict\n",
        "        weights = load(fp)\n",
        "\n",
        "        # iterate through layers\n",
        "        for l, w in zip(model.layers, weights.values()):\n",
        "            _dispatch_import_weights_layer_specific(l, w)\n",
        "\n",
        "    _dbg(\"Weight import complete.\")"
      ],
      "metadata": {
        "id": "jPkAKEvQpgrH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_file_path = workdir\n",
        "weights_file = 'weights_test'"
      ],
      "metadata": {
        "id": "-BPuGIbwscDA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_lenet()\n",
        "import_weights(model, file_path=weights_file_path, file_name=weights_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BniPPA3fsiK8",
        "outputId": "f7aa3619-7532-4821-b82d-a8a62f248177"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing weights from ./drive/MyDrive//weights_test.json\n",
            "\t - convolutional layer <quant_conv2d_2>\n",
            "\t\t - kernels\n",
            "\t - ignoring weightless layer <max_pooling2d_2>\n",
            "\t - batch normalization layer <batch_normalization_4>\n",
            "\t\t - means\n",
            "\t\t - variances\n",
            "\t - convolutional layer <quant_conv2d_3>\n",
            "\t\t - kernels\n",
            "\t - ignoring weightless layer <max_pooling2d_3>\n",
            "\t - batch normalization layer <batch_normalization_5>\n",
            "\t\t - means\n",
            "\t\t - variances\n",
            "\t - ignoring weightless layer <flatten_1>\n",
            "\t - dense layer <quant_dense_2>\n",
            "\t\t - weights\n",
            "\t - batch normalization layer <batch_normalization_6>\n",
            "\t\t - means\n",
            "\t\t - variances\n",
            "\t - dense layer <quant_dense_3>\n",
            "\t\t - weights\n",
            "\t - batch normalization layer <batch_normalization_7>\n",
            "\t\t - means\n",
            "\t\t - variances\n",
            "\t - ignoring weightless layer <activation_1>\n",
            "Weight import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight import test\n",
        "Evaluate the accuracy"
      ],
      "metadata": {
        "id": "dl89oKbqzlJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_x, test_y)\n",
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAoOcd5Ezv0t",
        "outputId": "ba44063b-ab7a-4b95-87bf-155d8c529cc7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.5347 - accuracy: 0.9439\n",
            "Test accuracy 94.39 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWfQNIBL8ygJ"
      },
      "source": [
        "# Intermediate layer output inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TErDZOV82dq"
      },
      "outputs": [],
      "source": [
        "def print_intermediate_results(model: tf.keras.Model,\n",
        "                               inp: np.ndarray,\n",
        "                               file: str = None,\n",
        "                               binary: bool = False):\n",
        "    \"\"\"Runs an inference on a model, printing all the intermediate results\n",
        "\n",
        "    Args:\n",
        "    - `model` -- the model object\n",
        "    - `inp` -- the input tensor (unbatched).\n",
        "    - `file` -- path to a text dump; if set,\n",
        "    it will not print to the standard output anymore\n",
        "    (default `None`)\n",
        "    - binary -- if yes, output the 32-bit binary representation\n",
        "    (default `False`)\n",
        "    \"\"\"\n",
        "\n",
        "    extractor_inputs = model.inputs\n",
        "    extractor_outputs = [layer.output for layer in model.layers]\n",
        "    layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "    result_extractor = tf.keras.Model(\n",
        "        inputs=extractor_inputs,\n",
        "        outputs=extractor_outputs\n",
        "    )\n",
        "\n",
        "    results = result_extractor(inp[None, :])  # dimension expansion\n",
        "\n",
        "    for lname, res in zip(layer_names, results):\n",
        "        int_res_list = np.trunc(res.numpy()).astype(np.int32).tolist()\n",
        "        str_int_res_list = [f\"{el}\\n\" for el in int_res_list]\n",
        "\n",
        "        print(f\"========================================================\\n\"\n",
        "              f\"{lname}:\\n\"\n",
        "            #   f\"{res.numpy().astype(np.int32)}\\n\"\n",
        "              f\"{str_int_res_list}\\n\"\n",
        "              f\"========================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJRQrz5t84HW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd4241b-9286-4972-9e8e-783b2e5ea5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================================\n",
            "quant_conv2d_2:\n",
            "['[[[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-3, -7, -3, -5, -11, 7, 1, 5], [-1, -5, -1, -7, -13, 9, 3, 3], [3, -5, 3, -7, -13, 9, 3, 3], [7, -5, 7, -7, -9, 13, 3, 3], [5, -7, 5, -5, -7, 11, 1, 5], [3, -5, 3, -3, -5, 9, -1, 7], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-1, -5, -5, -7, -13, 9, -1, 3], [-1, -1, -5, -11, -13, 13, 3, -1], [-1, -1, -5, -15, -17, 17, 7, -5], [1, 1, -3, -17, -11, 19, 13, -7], [5, 1, -3, -17, -11, 19, 9, -7], [7, -1, -1, -15, -9, 17, 7, -5], [5, -3, 1, -13, -11, 15, 5, -3], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [3, -5, 3, -11, -13, 13, 7, -1], [5, -3, 5, -9, -11, 11, 5, 1], [7, -5, 7, -7, -9, 13, 3, 3], [5, -7, 5, -5, -7, 11, 1, 5], [3, -5, 3, -3, -5, 9, -1, 7], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [3, -5, -1, -3, -9, 9, -5, 7], [-1, -1, -1, -3, -5, 9, -5, 3], [-5, 3, -5, -7, -5, 9, -1, -1], [-5, 7, -9, -7, -1, 9, 3, -5], [-1, 7, -17, -11, -1, 13, 7, -9], [1, 9, -19, -9, -3, 11, 5, -11], [5, 9, -15, -13, -7, 15, 5, -11], [5, 5, -11, -17, -11, 19, 5, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [5, 5, -7, -21, -11, 23, 9, -11], [3, 3, -5, -19, -9, 21, 11, -9], [7, 3, -1, -15, -9, 17, 7, -5], [11, -1, 3, -11, -5, 17, 3, -1], [7, -5, 3, -7, -5, 13, -1, 3], [3, -5, 3, -3, -5, 9, -1, 7], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -5, 3, 1, -5, 5, -5, 7], [-5, -5, 3, 1, -1, 1, -5, 7], [-9, -5, 3, 5, 3, -3, -1, 3], [-5, -1, 3, 9, 7, -7, 3, 3], [3, 7, -1, 9, 7, -7, -1, -1], [5, 9, -3, 7, 9, -5, -3, 1], [1, 9, -7, 3, 5, -1, -3, -3], [1, 9, -11, -1, 5, 3, 1, -7], [1, 13, -15, -5, 5, 7, 1, -11], [1, 13, -15, -5, 5, 7, 1, -11], [1, 13, -15, -5, 5, 7, 1, -11], [1, 13, -15, -5, 5, 7, 1, -11], [1, 13, -15, -5, 5, 7, 1, -11], [-1, 11, -17, -7, 3, 9, 3, -13], [-3, 13, -19, -9, 1, 7, 5, -15], [3, 15, -17, -11, -1, 9, 7, -13], [7, 7, -9, -7, -1, 13, 7, -9], [11, 3, -5, -7, -1, 13, 3, -5], [9, 1, -3, -5, 1, 11, -3, 1], [3, -5, -1, -3, -5, 9, -5, 7], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, 3, 1, -5, 5, -5, 11], [-5, -13, 7, 5, -1, 1, -5, 11], [-5, -13, 11, 9, -1, -3, -5, 15], [-5, -9, 15, 13, -1, -7, -9, 19], [-1, -9, 15, 17, 3, -11, -13, 15], [-3, -7, 9, 11, 5, -13, -7, 13], [-3, -7, 5, 11, 9, -13, -3, 9], [-3, -3, 5, 11, 9, -13, 1, 9], [1, 1, 5, 15, 13, -13, -3, 5], [1, 1, 5, 15, 13, -13, -3, 5], [1, 1, 5, 15, 13, -13, -3, 5], [1, 1, 5, 15, 13, -13, -3, 5], [1, 1, 5, 15, 13, -13, -3, 5], [1, 1, 1, 11, 9, -9, -3, 1], [-3, 5, -3, 7, 9, -9, 1, -3], [-1, 11, -1, 5, 7, -7, 7, -5], [11, 7, -1, 1, 3, 1, 7, -1], [15, 3, -1, 1, 7, 5, -1, -1], [11, -1, -1, 1, 3, 5, -5, 3], [3, -5, -1, 1, -5, 5, -5, 7], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, 3, 1, -5, 5, -5, 11], [-3, -11, 5, 3, -7, 3, -7, 13], [-5, -9, 7, 5, -9, 1, -9, 15], [-3, -11, 5, 7, -7, -1, -11, 13], [-7, -15, 5, 7, -7, -5, -11, 17], [-9, -17, 7, 9, -5, -7, -9, 15], [-7, -15, 9, 11, -3, -9, -7, 17], [-5, -13, 11, 13, -1, -11, -9, 19], [-3, -15, 13, 15, 1, -13, -11, 21], [-3, -15, 13, 15, 1, -13, -11, 21], [-3, -15, 13, 15, 1, -13, -11, 21], [-3, -15, 13, 15, 1, -13, -11, 21], [-5, -17, 11, 13, -1, -11, -9, 19], [-7, -11, 9, 11, -3, -13, -11, 13], [-7, -3, 9, 7, 1, -13, -7, 9], [-5, -5, 7, 5, -1, -7, 3, 7], [7, -1, 3, 5, 3, -3, 7, 3], [17, 1, -3, 3, 9, -1, -3, 5], [7, -5, -1, 1, -1, 1, -9, 11], [3, -9, 3, 1, -5, 5, -5, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, 3, 1, -5, 5, -5, 11], [-3, -11, 5, 3, -7, 3, -7, 13], [-5, -9, 7, 5, -9, 1, -9, 15], [-3, -11, 5, 7, -7, -1, -11, 13], [-5, -13, 3, 5, -9, -3, -9, 15], [-5, -13, 3, 5, -9, -3, -9, 15], [-5, -13, 3, 5, -9, -3, -9, 15], [-7, -15, 1, 3, -11, -1, -7, 13], [-7, -11, -3, -1, -15, -1, -7, 9], [-11, -7, 1, -1, -11, -1, -7, 5], [-15, -7, 5, -1, -7, -5, 1, 1], [-3, -3, 5, -1, -3, -1, 9, 1], [9, 1, 1, 3, 1, -1, 1, 5], [11, -1, -1, 5, 3, -3, -9, 7], [5, -11, -3, 3, -3, -1, -7, 9], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, -3, -5, -11, 11, -3, 5], [-5, -1, -5, -7, -9, 9, -1, -1], [-9, 3, -1, -7, -5, 5, -1, -1], [-9, -5, 3, -3, -1, 5, 7, -1], [3, 3, 3, 1, -1, 5, 7, -1], [15, 7, -1, 5, 7, 1, -5, 3], [9, -7, -3, 3, 1, -1, -11, 9], [1, -11, 1, -1, -7, 3, -3, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-3, -3, -3, -5, -11, 7, -3, 1], [-7, 1, -3, -9, -7, 7, 1, -3], [-13, -1, 3, -3, -1, 1, 7, -5], [1, 1, 5, -1, 1, 3, 13, -3], [11, 7, 3, 5, 3, 1, -1, 3], [13, 1, 1, 7, 5, -1, -11, 5], [5, -11, -3, 3, -3, -1, -7, 9], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, -3, -5, -11, 11, -3, 5], [-7, -3, -3, -5, -7, 7, -3, 1], [-11, 1, 1, -5, -3, 3, 1, -3], [-7, -3, 5, -1, 1, 3, 9, 1], [5, 5, 5, 3, 1, 3, 5, 1], [17, 5, 1, 7, 9, -1, -7, 5], [9, -7, -3, 3, 1, -1, -11, 9], [1, -11, 1, -1, -7, 3, -3, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -5, -1, -3, -9, 9, -5, 3], [-11, -3, -3, -5, -3, 3, -3, 1], [-17, -1, 3, 1, -1, -3, 3, -1], [-3, 1, 5, 3, -3, -1, 9, 1], [13, 5, 1, 7, 5, -1, -3, 1], [11, -1, -1, 5, 3, -3, -9, 7], [5, -11, -3, 3, -3, -1, -7, 9], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-5, -5, -1, -3, -9, 5, -5, 3], [-9, -1, 3, -3, -1, 1, -1, -1], [-9, -5, 7, 1, -1, 1, 7, 3], [3, 3, 7, 5, -1, 1, 7, 3], [17, 5, 1, 7, 9, -1, -7, 5], [9, -7, -3, 3, 1, -1, -11, 9], [1, -11, 1, -1, -7, 3, -3, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-1, -5, -5, -7, -13, 9, -1, 3], [-7, -3, 1, -5, -7, 7, -3, 1], [-13, -5, 7, -3, -5, 1, 3, -1], [-3, 1, 9, -1, -3, 3, 9, 1], [11, 3, 3, 5, 3, 1, -1, 3], [11, -1, -1, 5, 3, -3, -9, 7], [5, -11, -3, 3, -3, -1, -7, 9], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-1, -5, -5, -7, -13, 9, -1, 3], [-3, 1, -3, -9, -11, 11, 1, -3], [-7, 1, 1, -9, -7, 7, 1, -3], [-7, -3, 5, -5, 1, 7, 9, -3], [3, 3, 3, 1, -1, 5, 7, -1], [15, 7, -1, 5, 7, 1, -5, 3], [9, -7, -3, 3, 1, -1, -11, 9], [1, -11, 1, -1, -7, 3, -3, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, -3, -5, -11, 11, -3, 5], [-5, -1, -5, -7, -9, 9, -1, -1], [-7, 5, -3, -9, -7, 7, 1, -3], [-9, -1, 3, -3, 3, 5, 7, -5], [1, 1, 1, -1, 5, 3, 9, -3], [9, 9, 1, 7, 5, -1, -3, 5], [11, -1, -1, 9, 3, -3, -13, 7], [5, -11, -3, 3, -3, -1, -7, 9], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-3, -3, -3, -5, -11, 7, -3, 1], [-5, 3, -1, -7, -5, 5, -1, -1], [-11, -3, 5, -1, 1, 3, 5, -3], [-3, -3, 5, 3, 5, -1, 9, 1], [7, 7, 3, 9, 7, -3, -1, 3], [13, 1, 1, 11, 5, -5, -11, 9], [7, -9, -1, 5, -1, -3, -9, 11], [1, -11, 1, -1, -7, 3, -3, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -9, -1, -3, -9, 9, -1, 7], [-1, -5, -5, -7, -13, 9, -1, 3], [-5, -1, -1, -7, -9, 9, -1, -1], [-11, -3, 5, -5, -3, 3, 5, -3], [-3, -3, 9, -1, 1, 3, 9, 1], [5, 1, 9, 7, 5, -1, 1, 5], [13, 1, 5, 11, 5, -5, -11, 9], [5, -7, 1, 7, -3, -5, -11, 13], [3, -13, -1, 1, -5, 1, -5, 11], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, -3, -5, -11, 11, -3, 5], [-5, -1, -5, -7, -9, 9, -1, -1], [-11, 1, -3, -9, -7, 7, 1, -3], [-11, -3, 1, -5, -3, 3, 9, -3], [3, 3, 7, 1, -1, 5, 7, -1], [15, 3, 3, 5, 3, 1, -5, 3], [9, -3, 1, 3, 1, -1, -11, 9], [3, -13, -1, 1, -5, 1, -5, 11], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-1, -5, -1, -3, -9, 9, -5, 3], [-9, -1, -5, -7, -5, 5, -1, -1], [-15, 1, -3, -5, -3, 3, 5, -7], [-5, 3, -1, -3, -1, 1, 15, -5], [11, 11, 3, 1, -1, 5, 3, -1], [17, 1, 1, 3, 5, 3, -7, 1], [9, -7, -3, -1, 1, 3, -7, 5], [-1, -9, -1, -3, -9, 5, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-3, -7, 1, -1, -7, 7, -7, 5], [-13, -5, -1, -3, -1, 1, -1, -1], [-13, 3, 3, 1, -1, -3, 3, -1], [-1, 7, 3, 1, -1, 1, 11, -1], [15, 7, -1, 5, 7, 1, -1, -1], [15, -1, -5, 1, 7, 1, -5, 3], [5, -7, -3, -1, -3, 3, -7, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [-3, -7, 5, 3, -3, 3, -11, 9], [-11, -7, 5, 3, 1, -1, -7, 5], [-17, -1, 7, 9, 3, -7, -1, 7], [-1, 3, -1, 9, 3, -7, 3, 3], [11, 3, -5, 9, 7, -7, -5, 7], [11, -5, -5, 5, 3, -3, -9, 7], [3, -9, -1, 1, -5, 1, -5, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "max_pooling2d_2:\n",
            "['[[[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[3, -5, 1, -1, -7, 9, -1, 9], [-1, 7, -1, -3, -1, 17, 7, 7], [7, 9, 7, -5, -1, 19, 13, 5], [5, 5, 3, -1, -5, 23, 9, 9], [5, 5, 3, -1, -7, 23, 9, 9], [5, 5, 5, -1, -7, 23, 11, 9], [11, 3, 7, -1, -5, 17, 7, 9], [3, -5, 3, -1, -5, 9, -1, 9]], [[1, -5, 3, 1, -5, 7, -3, 11], [-3, -1, 15, 13, 7, 3, 3, 19], [5, 9, 15, 17, 9, -1, -1, 17], [1, 13, 13, 15, 13, 7, 1, 21], [1, 13, 13, 15, 13, 7, 1, 21], [3, 15, 9, 11, 9, 9, 7, 13], [17, 7, 3, 5, 9, 13, 7, 11], [3, -5, 3, 1, -5, 9, -3, 11]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 7, 5, -5, 7, -3, 15], [1, -7, 5, 7, -7, 7, -3, 15], [1, 1, 3, 5, -7, 11, 1, 15], [11, 7, 5, 5, 3, 5, 13, 5], [15, 7, 1, 7, 7, 5, 1, 13], [1, -7, 1, -1, -7, 7, -1, 11]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 9, -1, 9], [1, 1, 7, 1, -1, 11, 7, 5], [17, 5, 7, 7, 9, 3, 9, 9], [9, -7, 1, 3, 1, 7, -1, 13], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, 5, 1, -1, -7, 11, 1, 9], [9, 9, 9, 7, 5, 7, 9, 5], [15, 7, 3, 9, 7, 5, -1, 13], [1, -7, 1, -1, -7, 7, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -1, 1, -1, -7, 11, -1, 9], [3, 3, 9, 1, 1, 9, 9, 1], [15, 7, 9, 11, 7, 1, 9, 13], [7, -7, 1, 5, -1, 7, -1, 13], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]], [[1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -1, 5, 3, 1, 9, -1, 9], [15, 11, 7, 9, 7, 5, 15, 7], [17, 1, 1, 5, 7, 7, -1, 11], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9], [1, -7, 1, -1, -7, 7, -3, 9]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "batch_normalization_4:\n",
            "['[[[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [-1, 1, -1, -1, 0, 1, 0, 0], [0, 1, 0, -1, 0, 2, 1, 0], [0, 0, 0, 0, 0, 2, 1, 0], [0, 0, 0, 0, -1, 2, 1, 0], [0, 0, 0, 0, -1, 2, 1, 0], [1, 0, 0, 0, 0, 1, 0, 0], [0, -1, 0, 0, 0, 0, 0, 0]], [[0, -1, 0, 0, 0, 0, 0, 0], [-1, 0, 2, 1, 0, 0, 0, 1], [0, 1, 2, 2, 1, -1, 0, 1], [0, 2, 2, 1, 1, 0, 0, 2], [0, 2, 2, 1, 1, 0, 0, 2], [0, 2, 1, 1, 1, 0, 0, 0], [2, 1, 0, 0, 1, 1, 0, 0], [0, -1, 0, 0, 0, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, 0, 0, 0, -1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 1, 0, 1, 0], [0, -1, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, 0, 0, 0, -1, 0, 0, 0], [0, 1, 1, 0, 0, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, 0, 0, 0, -1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 1, -1], [1, 1, 1, 1, 0, -1, 1, 0], [0, -1, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]], [[0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 2, 0], [2, 0, 0, 0, 0, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0], [0, -1, 0, 0, -1, 0, 0, 0]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "quant_conv2d_3:\n",
            "['[[[-12, 24, 36, 20, 18, 12, 2, -24, 18, -8, 6, 12, -12, -4, -10, 4, 4, -4, -6, -14, 10, -4, 10, 24, 18, -14, -4, 20, -16, -18, -22, 8], [-2, -2, 26, 22, 20, 2, 8, -38, 4, -6, -8, 30, -30, 2, -28, 14, -2, -10, -4, -16, 16, -6, 8, 34, 0, 0, 2, 6, 6, -8, -32, 18], [2, -6, 22, 18, 20, -6, -8, -34, 4, -14, -8, 34, -30, 6, -16, 10, -2, -14, -12, -16, 12, -2, 8, 34, 4, -4, 14, -6, 10, -4, -32, 26], [0, 0, 20, 16, 14, 0, -6, -32, 14, -12, -2, 28, -28, 0, -18, 8, 0, -12, -6, -14, 14, 4, 6, 40, 2, -6, 12, 0, 4, -6, -26, 24], [-8, 8, 20, 16, 6, 4, -2, -28, 14, -12, -6, 28, -24, 0, -18, 0, 0, -8, 2, -10, 10, 0, 2, 32, 6, -6, 8, 8, 4, -2, -30, 24], [-10, -10, 10, 22, 0, -10, 12, -30, -4, 6, -8, 18, -18, 10, -20, 2, -22, -6, 0, -20, -4, -14, 0, 10, -12, 4, 2, -6, 22, 12, -24, 10]], [[-10, 14, 2, 6, 8, 6, 24, -6, -12, 2, 32, -26, 22, 22, -16, 6, -6, 26, -16, 20, -8, -6, 0, -6, 8, -4, -38, 10, -30, 16, 20, -18], [2, 22, -10, 2, 28, -6, 4, -2, -24, 6, 32, -18, 26, 30, -12, -2, -6, 22, -20, 28, 0, 14, 16, 10, 8, -8, -30, 2, -18, 16, 32, -10], [0, 20, -16, -12, 18, -12, -10, -4, -10, -8, 34, -8, 16, 28, -18, 0, 8, 24, -18, 30, 2, 12, 22, 12, 18, -18, -20, 0, -8, 14, 14, -8], [-2, 30, -6, -10, 24, 2, -8, 6, -8, -18, 20, -10, 14, 22, -8, 6, 14, 22, -12, 32, 8, 10, 12, 10, 12, -24, -14, 2, -14, 12, 8, 2], [-24, 36, 4, 8, 30, 20, 2, 0, -10, -24, 6, -4, 8, 16, -14, 12, 4, 16, -14, 26, 14, 16, 6, 8, 10, -6, -12, 20, -8, 10, -14, 8], [6, 6, -10, 18, 20, -18, 4, -10, -28, -2, -8, -2, -10, 22, -8, 10, -18, 10, -16, 0, 4, -6, 4, 14, -24, 12, -2, -14, 26, 12, 4, 14]], [[2, -10, -6, -2, -24, -6, 24, 14, 4, 34, 0, -6, 22, -6, 16, -10, -14, 10, 16, -12, -16, -18, 0, -14, -4, 4, -10, -2, -14, 12, 20, -14], [8, -12, -20, -20, -26, -8, 6, 20, 2, 36, 6, -8, 36, -4, 30, -16, -12, 12, 22, 6, -14, 0, 6, -20, 2, -6, -8, -12, -12, 6, 26, -20], [2, -2, -22, -34, -20, 2, -8, 30, 12, 30, 4, -6, 30, -22, 36, -14, 2, 14, 12, 4, -24, 6, 0, -22, 0, -8, 6, -6, -14, 4, 20, -18], [-14, 10, 2, -22, -4, 34, -8, 22, 20, 6, 0, -2, 18, -22, 28, -6, 10, 6, 16, 8, 0, 18, -4, -10, 4, -4, 6, 26, -26, -4, 0, -6], [-28, -8, -4, 0, -2, 28, 26, 4, 2, -4, -14, -8, 0, 0, -2, 4, 0, 8, 6, 2, 14, 4, -10, -12, -14, 38, -8, 32, -8, 14, -2, -12], [26, -14, -30, -2, 0, -34, -12, -2, -24, 6, -12, -6, -2, 10, 4, -10, -22, -2, -4, 4, -4, -2, -4, -2, -20, 12, -2, -26, 22, 12, 8, 6]], [[6, 2, 6, 6, -8, -18, 12, -10, 0, 26, 8, -6, 10, -2, 8, -14, -14, 10, 0, -16, -28, -22, -4, -6, 0, -12, -14, -6, 2, 8, 4, -6], [10, 2, -2, 2, -12, -10, 8, -2, 4, 30, 4, 2, 10, -10, 16, -22, -18, 2, 8, -20, -24, -14, -4, -2, 0, -12, -6, -2, 2, 0, 0, -6], [6, 6, 2, -10, -16, 14, -4, 6, 28, 22, 0, 2, 2, -26, 28, -14, -6, -6, 8, -12, -4, -2, -8, 2, 8, -12, 6, 10, -10, -16, -4, 10], [-32, 0, 24, 12, -10, 44, 22, 0, 18, 0, -6, 4, -4, -8, -6, 16, 8, 0, 14, -10, 6, 8, -10, -16, 14, 10, 0, 36, -24, -10, -22, -4], [0, -16, -12, 20, 2, 0, 22, -8, -18, 4, -30, 0, -4, 20, -6, 16, -12, -8, -2, -6, 6, -4, -2, 0, -26, 34, -4, 0, 16, 18, 2, 0], [38, -14, -26, -18, -8, -42, -36, -2, -8, 10, -4, 6, 6, 2, 12, -18, -10, -10, -4, 4, -4, 2, 4, -2, 0, -12, 6, -38, 18, 4, 8, -6]], [[4, 8, 4, 8, -6, -20, 10, -16, -2, 20, 10, -12, 12, 0, 6, -16, -16, 8, -6, -14, -22, -28, -6, -4, 2, -6, -20, -4, -4, 6, 6, -8], [10, 14, 6, 2, -4, -10, 0, -10, 8, 10, 8, -6, 6, -10, 12, -18, -6, 2, -8, -16, -20, -18, -8, 6, 4, -12, -10, -2, -6, -4, 4, 2], [-20, 20, 36, 8, 6, 24, 6, -8, 18, -8, 14, 0, 0, -8, -6, 4, 4, 4, -2, -2, 6, 4, -2, 8, 22, -10, -8, 20, -20, -14, -18, 8], [-28, -4, 20, 32, 2, 24, 42, -12, -18, -8, 2, 0, -8, 16, -26, 28, -8, 12, 2, -6, 10, -8, -2, -4, -6, 26, -16, 20, -4, 14, -6, 0], [26, -14, -26, 2, 4, -30, -4, -6, -32, 2, -8, 2, 2, 22, 0, -10, -18, -2, -4, 4, 0, -10, 8, 10, -28, 12, -6, -14, 26, 24, 16, 2], [20, 4, -20, -20, -6, -40, -30, 0, 6, 8, 10, -8, 16, -8, 18, -24, 4, 0, -10, 10, -14, -8, -2, -8, 10, -18, 0, -20, 4, 2, 14, -12]], [[8, 8, 8, 4, -2, -16, 6, -12, 2, 16, 10, -8, 8, -4, 10, -16, -12, 4, -6, -14, -18, -24, -6, 0, 2, -10, -16, -4, -8, 2, 6, -4], [-4, 24, 20, 4, 2, 8, -6, -12, 18, 4, 14, -8, 4, -12, 2, -4, 4, 0, -6, -6, -2, -4, -2, 12, 18, -14, -8, 16, -20, -18, -6, 8], [-34, 10, 26, 18, 4, 34, 36, -14, 0, -14, 0, 2, -2, 6, -24, 18, 6, 18, 4, 0, 4, -6, 0, -2, 12, 8, -18, 34, -10, 0, -16, 2], [12, -12, -12, 8, 2, -16, 26, 0, -30, 0, -22, 4, -8, 28, -10, 8, -16, 0, -2, -2, 2, -4, -6, -4, -30, 30, -12, -4, 12, 34, 14, 12], [30, -6, -34, -22, -8, -34, -40, 6, -4, 10, -8, 2, 14, -2, 20, -26, -10, -6, -4, 8, -12, 6, 0, 2, -4, -16, 6, -30, 14, 12, 12, -10], [-4, 4, -4, -8, -10, -20, -6, -4, 14, 24, 6, -16, 16, -20, 18, -16, -4, 12, -6, -10, -22, -20, -10, -12, 6, -10, -4, -8, -8, -6, 2, -16]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "max_pooling2d_3:\n",
            "['[[[2, 24, 36, 22, 28, 12, 24, -2, 18, 6, 32, 30, 26, 30, -10, 14, 4, 26, -4, 28, 16, 14, 16, 34, 18, 0, 2, 20, 6, 16, 32, 18], [2, 30, 22, 18, 24, 2, -6, 6, 14, -8, 34, 34, 16, 28, -8, 10, 14, 24, -6, 32, 14, 12, 22, 40, 18, -4, 14, 2, 10, 14, 14, 26], [6, 36, 20, 22, 30, 20, 12, 0, 14, 6, 6, 28, 8, 22, -8, 12, 4, 16, 2, 26, 14, 16, 6, 32, 10, 12, 8, 20, 26, 12, 4, 24]], [[10, 2, 6, 6, -8, -6, 24, 20, 4, 36, 8, 2, 36, -2, 30, -10, -12, 12, 22, 6, -14, 0, 6, -2, 2, 4, -6, -2, 2, 12, 26, -6], [6, 10, 24, 12, -4, 44, 22, 30, 28, 30, 4, 4, 30, -8, 36, 16, 10, 14, 16, 8, 6, 18, 0, 2, 14, 10, 6, 36, -10, 4, 20, 10], [38, -8, -4, 20, 2, 28, 26, 4, 2, 10, -4, 6, 6, 20, 12, 16, 0, 8, 6, 4, 14, 4, 4, 0, 0, 38, 6, 32, 22, 18, 8, 6]], [[10, 24, 20, 8, 2, 8, 10, -10, 18, 20, 14, -6, 12, 0, 12, -4, 4, 8, -6, -6, -2, -4, -2, 12, 18, -6, -8, 16, -4, 6, 6, 8], [12, 20, 36, 32, 6, 34, 42, 0, 18, 0, 14, 4, 0, 28, -6, 28, 6, 18, 4, 0, 10, 4, 0, 8, 22, 30, -8, 34, 12, 34, 14, 12], [30, 4, -4, 2, 4, -20, -4, 6, 14, 24, 10, 2, 16, 22, 20, -10, 4, 12, -4, 10, 0, 6, 8, 10, 10, 12, 6, -8, 26, 24, 16, 2]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "batch_normalization_5:\n",
            "['[[[-1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, -1, 0, 0, 1, -1, 1, 0, 0, 0, 1, 0, -1, 0, 0, 0, 0, 1, 0], [-1, 1, 0, 0, 0, 0, -1, 0, 0, -1, 2, 2, 0, 0, -1, 0, 0, 1, -1, 1, 0, 0, 1, 2, 0, -1, 0, 0, 0, 0, 0, 1], [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]], [[0, -1, 0, 0, -1, -1, 0, 1, 0, 2, 0, 0, 2, -1, 2, -1, -2, 0, 1, 0, -2, 0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1], [0, 0, 0, 0, -1, 2, 0, 2, 1, 1, 0, 0, 1, -1, 2, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 1, -1, 0, 0, 0], [2, -1, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 2, 0, 1, 0, 0, 0, 0]], [[0, 1, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, -1, 0, -1, 0, 0, 0], [0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, -1, 1, 0, 2, 0, 0], [1, 0, -1, -1, 0, -2, -1, 0, 0, 1, 0, 0, 0, 0, 1, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1, 1, 0, 0]]]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "flatten_1:\n",
            "['[-1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, -1, 0, 0, 1, -1, 1, 0, 0, 0, 1, 0, -1, 0, 0, 0, 0, 1, 0, -1, 1, 0, 0, 0, 0, -1, 0, 0, -1, 2, 2, 0, 0, -1, 0, 0, 1, -1, 1, 0, 0, 1, 2, 0, -1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, -1, 0, 0, -1, -1, 0, 1, 0, 2, 0, 0, 2, -1, 2, -1, -2, 0, 1, 0, -2, 0, 0, -1, 0, 0, -1, -1, 0, 0, 1, -1, 0, 0, 0, 0, -1, 2, 0, 2, 1, 1, 0, 0, 1, -1, 2, 0, 0, 0, 0, 0, 0, 0, -1, -1, 0, 0, 0, 1, -1, 0, 0, 0, 2, -1, -1, 0, -1, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, -1, 0, 0, -1, 0, 0, 0, -1, 0, -1, 0, -1, 0, 0, -1, -1, -1, 0, -1, 0, 0, -1, -1, 0, -1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 1, -1, 1, 0, 2, 0, 0, 1, 0, -1, -1, 0, -2, -1, 0, 0, 1, 0, 0, 0, 0, 1, -1, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1, 1, 0, 0]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "quant_dense_2:\n",
            "['[-10, -8, 22, -34, -68, -64, -20, 26, 18, 48, -34, -30, -12, -70, 38, 6, -30, 42, -2, 32, -84, -20, 30, 24, 58, -52, 32, -38, 18, 32, -10, 30, -44, -26, 28, -6, -20, -24, -28, -32, 44, 40, -16, 22, 14, 6, -16, -22, 4, 32, 54, 38, -32, 10, -30, 24, -20, -4, 36, 28, -40, -24, -32, 70]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "batch_normalization_6:\n",
            "['[0, 0, 1, 0, -1, -2, -1, 0, 0, 1, -1, 0, 0, -2, 1, 0, 0, 1, 0, 1, -2, -1, 0, 1, 2, -1, 1, 0, 0, 1, 0, 0, -1, 0, 0, 0, -1, 0, 0, -1, 1, 1, 0, 0, 0, 0, 0, -1, 0, 1, 1, 1, -1, 0, -1, 1, -1, 0, 1, 1, -1, -1, 0, 2]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "quant_dense_3:\n",
            "['[-8, 0, -6, -2, -8, -8, 0, 56, -10, 0]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "batch_normalization_7:\n",
            "['[0, 0, 0, 0, 0, 0, 0, 3, 0, 0]\\n']\n",
            "========================================================\n",
            "========================================================\n",
            "activation_1:\n",
            "['[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n']\n",
            "========================================================\n"
          ]
        }
      ],
      "source": [
        "print_intermediate_results(model, test_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmd6O5DHKPPM"
      },
      "source": [
        "# Weight extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppnchQ3J8L0i"
      },
      "outputs": [],
      "source": [
        "def _extract_dense_weights(layer_name: str,\n",
        "                           weight_list: List,\n",
        "                           dtype: np.dtype | str = np.float32) -> Dict:\n",
        "    ret = dict()\n",
        "\n",
        "    if len(weight_list) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - weights\\n\"\n",
        "             f\"\\t\\t - biases\")\n",
        "        ret['weights'] = weight_list[0].astype(dtype).tolist()\n",
        "        ret['biases'] = weight_list[1].astype(dtype).tolist()\n",
        "    elif len(weight_list) == 1:\n",
        "        # without biases\n",
        "        _dbg(f\"\\t\\t - weights\")\n",
        "        ret['weights'] = weight_list[0].astype(dtype).tolist()\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBNka5Yk8LvR"
      },
      "outputs": [],
      "source": [
        "def _extract_bn_weights(layer_name: str,\n",
        "                        weight_list: List,\n",
        "                        dtype: np.dtype | str = np.float32) -> Dict:\n",
        "    ret = dict()\n",
        "\n",
        "    if len(weight_list) == 2:\n",
        "        # no betas, gammas\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - means\\n\"\n",
        "             f\"\\t\\t - variances\")\n",
        "        ret['means'] = weight_list[0].astype(dtype).tolist()\n",
        "        ret['vars'] = weight_list[1].astype(dtype).tolist()\n",
        "    elif len(weight_list) == 4:\n",
        "        # with betas, gammas\n",
        "        _dbg(f\"\\t\\t - means\\n\"\n",
        "             f\"\\t\\t - variances\\n\"\n",
        "             f\"\\t\\t - betas\\n\"\n",
        "             f\"\\t\\t - gammas\")\n",
        "        raise NotImplementedError('Extracting weights is not implemented for batch normalization with scaling and centering.')\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTqx7dD48LpC"
      },
      "outputs": [],
      "source": [
        "def _extract_conv_weights(layer_name: str,\n",
        "                          weight_list: List,\n",
        "                          dtype: np.dtype | str = np.float32) -> Dict:\n",
        "    ret = dict()\n",
        "\n",
        "    if len(weight_list) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        _dbg(f\"\\t\\t - kernels\\n\"\n",
        "             f\"\\t\\t - biases\")\n",
        "        ret['kernels'] = weight_list[0].astype(dtype).tolist()\n",
        "        ret['biases'] = weight_list[1].astype(dtype).tolist()\n",
        "    elif len(weight_list) == 1:\n",
        "        # without biases\n",
        "        _dbg(f\"\\t\\t - kernels\")\n",
        "        ret['kernels'] = weight_list[0].astype(dtype).tolist()\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGDT7vqO7fCh"
      },
      "outputs": [],
      "source": [
        "def _dispatch_extract_weights_layer_specific(layer_name: str,\n",
        "                                             weight_list: List,\n",
        "                                             dtype: np.dtype | str = np.float32) -> Dict:\n",
        "    weightless_layers = ['pool', 'flatten', 'activation']\n",
        "\n",
        "    if 'conv2d' in layer_name:\n",
        "        _dbg(f\"\\t - convolutional layer <{layer_name}>\")\n",
        "        return _extract_conv_weights(layer_name, weight_list, dtype)\n",
        "    elif 'batch_normalization' in layer_name:\n",
        "        _dbg(f\"\\t - batch normalization layer <{layer_name}>\")\n",
        "        return _extract_bn_weights(layer_name, weight_list, dtype)\n",
        "    elif 'dense' in layer_name:\n",
        "        _dbg(f\"\\t - dense layer <{layer_name}>\")\n",
        "        return _extract_dense_weights(layer_name, weight_list, dtype)\n",
        "    elif any([wl in layer_name for wl in weightless_layers]):\n",
        "        # a supported layer that has no weights\n",
        "        _dbg(f\"\\t - ignoring weightless layer <{layer_name}>\")\n",
        "        return dict()\n",
        "    else:\n",
        "        raise ValueError('This layer type is not supported.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMRwxQEL-wQm"
      },
      "outputs": [],
      "source": [
        "def extract_weights(model: tf.keras.Model,\n",
        "                    quantized: bool = False,\n",
        "                    file_path: str = None,\n",
        "                    file_name: str = None,\n",
        "                    dtype: np.dtype | str = np.float32) -> Dict:\n",
        "    \"\"\"Extracts the (quantized) weights from the model.\n",
        "    Optionally saves them in a file.\n",
        "\n",
        "    Args:\n",
        "    `model` -- neural net model\n",
        "    `quantized` -- set to true if you want to export `larq`-quantized weights\n",
        "    (default `False`)\n",
        "    `file_path` -- path to resulting file. if `None`, weights are not saved\n",
        "    (default `None`)\n",
        "    `file_name` -- name of the resulting file (default `None`)\n",
        "    `dtype` -- data type to save the weights as (default `np.float32`)\n",
        "\n",
        "    Returns:\n",
        "    `Dict` containing the weights for each layer\n",
        "    \"\"\"\n",
        "\n",
        "    _dbg(f\"Extracting weights {f'to {file_path}/{file_name}.json' if file_path else ''}\")\n",
        "\n",
        "    ret = dict()\n",
        "    name_idx_dict = dict()\n",
        "\n",
        "    # build weight dictionary\n",
        "    with lq.context.quantized_scope(quantized):\n",
        "        for layer in model.layers:\n",
        "            # get layer raw name and info\n",
        "            layer_cfg = layer.get_config()\n",
        "            weight_list = layer.get_weights()\n",
        "            weight_list_len = len(weight_list)\n",
        "\n",
        "            # adjust layer name\n",
        "            ## you want to replace the trailing index of the layer,\n",
        "            ## because that increases each time you create a new model\n",
        "            ## in the same session\n",
        "            last_underscore_idx = layer_cfg['name'].rfind('_')\n",
        "            raw_name = layer_cfg['name'][:last_underscore_idx]\n",
        "            if raw_name not in name_idx_dict:\n",
        "                name_idx_dict[raw_name] = 1\n",
        "            else:\n",
        "                name_idx_dict[raw_name] += 1\n",
        "            name = f'{raw_name}_{name_idx_dict[raw_name]}'\n",
        "\n",
        "            # add (name, (weights)) pair in dictionary\n",
        "            ret[name] = _dispatch_extract_weights_layer_specific(name, weight_list, dtype)\n",
        "\n",
        "    # save dictionary to file if requested\n",
        "    if file_path is not None:\n",
        "        with open(f'{file_path}{file_name}.json', 'w') as fp:\n",
        "            dump(ret, fp)\n",
        "\n",
        "    _dbg(\"Weight extraction complete.\")\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRVaABYE_YLa"
      },
      "outputs": [],
      "source": [
        "weights_file_path = workdir\n",
        "weights_file = 'weights_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBSKuuZiFwww"
      },
      "outputs": [],
      "source": [
        "lq_int_model_dict = extract_weights(lq_int_model, quantized=True, file_path=weights_file_path, file_name=weights_file, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQH1zMyclZI9"
      },
      "source": [
        "# BatchNorm compensation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvmgbcbPljdX"
      },
      "source": [
        "TODO: adjust the weights, so that the batchnorm can be a single comparator in hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KyNeofkytDsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c0fa87-430f-4a1c-c17e-e3fac666862b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding compensation to weights from ./drive/MyDrive//weights_test.json to ./drive/MyDrive//weights_compensated.json\n"
          ]
        }
      ],
      "source": [
        "def add_to_bn(value: int, bn: Dict):\n",
        "    bn[\"means\"] = [int(np.ceil((x + value)/2)) for x in bn[\"means\"]]\n",
        "\n",
        "def add_compensation_to_batchnorm(weights_in: Dict | str,\n",
        "                           weights_out: str) -> None:\n",
        "    \"\"\"Adds weigth size to batchnorm for compensation.\n",
        "\n",
        "    Args:\n",
        "    `weights_in` -- object contains weights or path to json\n",
        "    `weights_out` -- the path of the output `.json` file\n",
        "    \"\"\"\n",
        "    _dbg(f\"Adding compensation to weights from \"\n",
        "         f\"{weights_in if type(weights_in) == str else 'pre-loaded model'} \"\n",
        "         f\"to {weights_out}\")\n",
        "\n",
        "    # load weights in memory if a file was provided\n",
        "    if type(weights_in) == str:\n",
        "        with open(weights_in, 'r') as fp:\n",
        "            weights_in = load(fp)\n",
        "\n",
        "    # Sanity check, don't compensate twice. Put key in skipped layer to prevent\n",
        "    # serialisation issues.\n",
        "    key = \"COMPENSATED\"\n",
        "    if key in weights_in[\"activation_1\"]:\n",
        "      print(\"Skipping, input already compensated\")\n",
        "      return\n",
        "\n",
        "    weights_in[\"activation_1\"][key] = 1\n",
        "\n",
        "    add_to_bn(5*5*1, weights_in[\"batch_normalization_1\"])  ## ioan -- sure these are correct?\n",
        "    add_to_bn(3*3*8, weights_in[\"batch_normalization_2\"])\n",
        "    add_to_bn(288, weights_in[\"batch_normalization_3\"])\n",
        "\n",
        "    # Don't compensate last batch norm,\n",
        "    # add_to_bn(64, weights_in[\"batch_normalization_4\"])\n",
        "\n",
        "    # write the .json file\n",
        "    if weights_out is not None:\n",
        "        with open(f'{weights_out}', 'w') as fp:\n",
        "            dump(weights_in, fp)\n",
        "\n",
        "weights_out = f'{workdir}/weights_compensated.json'\n",
        "add_compensation_to_batchnorm(f'{workdir}/weights_test.json', weights_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyfODMD5c4l8"
      },
      "source": [
        "# VHDL weight file generation\n",
        "\n",
        "**What is the objective?**\n",
        "\n",
        "Build a script that generates a VHDL file containing the hard-coded weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "SSuMZ62SKuhz"
      },
      "outputs": [],
      "source": [
        "def convert_to_2s_complement(num: int) -> str:\n",
        "    \"\"\"Converts a number to its 2's complement representation.\"\"\"\n",
        "\n",
        "    if num < 0:\n",
        "        num = 2 ** 32 + num\n",
        "\n",
        "    return f\"{num:032b}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "I5xpZJlwv7iN"
      },
      "outputs": [],
      "source": [
        "def _export_quant_dense_weights_to_vhdl_weights(fp, layer_name: str, weights: np.ndarray):\n",
        "\n",
        "    num_inputs = weights.shape[0]\n",
        "    num_outputs = weights.shape[1]\n",
        "\n",
        "    total_size = num_inputs * num_outputs\n",
        "\n",
        "    ##convert to n_out x n_in###\n",
        "    weights = weights.transpose()\n",
        "    #####\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS_DIM_NUM_IN : integer := {num_inputs};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS_DIM_NUM_OUT : integer := {num_outputs};\\n\")\n",
        "\n",
        "    # write weights\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS : std_logic_vector(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(weights.flatten()):\n",
        "        repr_el = 0 if el == -1 else 1  # binary representation of el\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\'{repr_el}\\'\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_dense_weights_to_vhdl_weights(fp, layer_name: str, weights: np.ndarray):\n",
        "\n",
        "    num_inputs = weights.shape[0]\n",
        "    num_outputs = weights.shape[1]\n",
        "\n",
        "    total_size = num_inputs * num_outputs\n",
        "\n",
        "    ##convert to n_out x n_in###\n",
        "    weights = weights.transpose()\n",
        "    #####\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS_DIM_NUM_IN : integer := {num_inputs};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS_DIM_NUM_OUT : integer := {num_outputs};\\n\")\n",
        "\n",
        "    # write weights\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_WEIGHTS : t_weight_array(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(weights.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 16 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_quant_dense_weights_to_vhdl_biases(fp, layer_name: str, biases: np.ndarray):\n",
        "    raise NotImplementedError(\"Quantized dense layers with biases are not supported.\")\n",
        "\n",
        "\n",
        "def _export_dense_weights_to_vhdl_biases(fp, layer_name: str, biases: np.ndarray):\n",
        "    raise NotImplementedError(\"Dense layers with biases are not supported.\")\n",
        "\n",
        "\n",
        "def _export_dense_weights_to_vhdl(fp, layer_name: str,\n",
        "                                  layer_data: Dict,\n",
        "                                  quantized: bool = False):\n",
        "\n",
        "    # set functions according to the quantization flag\n",
        "    if quantized:\n",
        "        export_weights = _export_quant_dense_weights_to_vhdl_weights\n",
        "        export_biases = _export_quant_dense_weights_to_vhdl_biases\n",
        "    else:\n",
        "        export_weights = _export_dense_weights_to_vhdl_weights\n",
        "        export_biases = _export_dense_weights_to_vhdl_biases\n",
        "\n",
        "    if len(layer_data.keys()) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        weights = np.array(layer_data['weights'])\n",
        "        biases = np.array(layer_data['biases'])\n",
        "        _dbg(f\"\\t\\t - weights (shape {weights.shape})\\n\"\n",
        "             f\"\\t\\t - biases (shape {biases.shape})\")\n",
        "        export_weights(fp, layer_name, weights)\n",
        "        export_biases(fp, layer_name, biases)\n",
        "    elif len(layer_data.keys()) == 1:\n",
        "        # without biases\n",
        "        weights = np.array(layer_data['weights'])\n",
        "        _dbg(f\"\\t\\t - weights (shape {weights.shape})\")\n",
        "        export_weights(fp, layer_name, weights)\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "XaXMvM-Dv-rR"
      },
      "outputs": [],
      "source": [
        "def _export_bn_weights_to_vhdl_means(fp, layer_name: str, means: np.ndarray):\n",
        "\n",
        "    num_means = means.shape[0]\n",
        "\n",
        "    total_size = num_means\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_MEANS_NUM : integer := {num_means};\\n\")\n",
        "\n",
        "    # write weights (first as std_logic)\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_MEANS : t_weight_array(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(means.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "    # write weights (then as std_logic_vector)\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_MEANS_VECTOR : std_logic_vector(0 to {total_size * 32 - 1}) := (\")\n",
        "    for idx, el in enumerate(means.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{' & ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_bn_weights_to_vhdl_vars(fp, layer_name: str,\n",
        "                                    vars: np.ndarray,\n",
        "                                    invert: bool = False,\n",
        "                                    fixed_pos: int = 10):\n",
        "\n",
        "    num_vars = vars.shape[0]\n",
        "\n",
        "    total_size = num_vars\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_VARS_NUM : integer := {num_vars};\\n\")\n",
        "\n",
        "    # write weights\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_VARS : t_weight_array(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(vars.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "    # if you don't want fixed point inverted vars in your file, return here\n",
        "    if not invert:\n",
        "        return\n",
        "\n",
        "    # compute inverted vars\n",
        "    ## compute floating point inverted vars\n",
        "    raw_inv_vars = (1 / vars).astype(np.float32)\n",
        "    ## extract exponents of the floating representation (unbiased)\n",
        "    inv_exps = np.array([frexp(el)[1] for el in raw_inv_vars])\n",
        "    ## compute largest exponen\n",
        "    max_inv_exp = np.max(inv_exps)\n",
        "    ## compute the number of shifts\n",
        "    amount_to_shift = np.abs(fixed_pos - max_inv_exp)\n",
        "    ## adjust and convert to unsigned\n",
        "    inv_vars = (raw_inv_vars * (2 ** amount_to_shift)).astype(np.uint32)\n",
        "\n",
        "    _dbg(f\"\\t\\t - shifting inverted vars {amount_to_shift} times to the left\")\n",
        "\n",
        "    # write inverted vars (as std_logic)\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_INV_VARS : t_weight_array(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(inv_vars.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "    # write inverted vars (as std_logic_vector)\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_INV_VARS_VECTOR : std_logic_vector(0 to {total_size * 32 - 1}) := (\")\n",
        "    for idx, el in enumerate(inv_vars.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{' & ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_bn_weights_to_vhdl_betas(fp, layer_name: str, betas: np.ndarray):\n",
        "    raise NotImplementedError(\"Batch normalization layers with betas are not supported.\")\n",
        "\n",
        "\n",
        "def _export_bn_weights_to_vhdl_gammas(fp, layer_name: str, gammas: np.ndarray):\n",
        "    raise NotImplementedError(\"Batch normalization layers with gammas are not supported.\")\n",
        "\n",
        "\n",
        "def _export_bn_weights_to_vhdl(fp, layer_name: str,\n",
        "                               layer_data: Dict,\n",
        "                               invert_vars: bool = False,\n",
        "                               inverted_vars_prec: int = 10):\n",
        "\n",
        "    if len(layer_data.keys()) == 2:\n",
        "        # no betas, gammas\n",
        "        # make sure this is indeed the correct order\n",
        "        means = np.array(layer_data['means'])\n",
        "        vars = np.array(layer_data['vars'])\n",
        "        _dbg(f\"\\t\\t - means (shape {means.shape})\\n\"\n",
        "             f\"\\t\\t - variances (shape {vars.shape})\")\n",
        "        _export_bn_weights_to_vhdl_means(fp, layer_name, means)\n",
        "        _export_bn_weights_to_vhdl_vars(fp, layer_name, vars, invert_vars, inverted_vars_prec)\n",
        "    elif len(layer_data.keys()) == 4:\n",
        "        # with betas, gammas\n",
        "        means = np.array(layer_data['means'])\n",
        "        vars = np.array(layer_data['vars'])\n",
        "        betas = np.array(layer_data['betas'])\n",
        "        gammas = np.array(layer_data['gammas'])\n",
        "        _dbg(f\"\\t\\t - means (shape {means.shape})\\n\"\n",
        "             f\"\\t\\t - variances (shape {vars.shape})\\n\"\n",
        "             f\"\\t\\t - betas (shape {betas.shape})\\n\"\n",
        "             f\"\\t\\t - gammas (shape {gammas.shape})\")\n",
        "        _export_bn_weights_to_vhdl_means(fp, layer_name, means)\n",
        "        _export_bn_weights_to_vhdl_vars(fp, layer_name, vars, invert_vars, inverted_vars_prec)\n",
        "        _export_bn_weights_to_vhdl_betas(fp, layer_name, betas)\n",
        "        _export_bn_weights_to_vhdl_gammas(fp, layer_name, gammas)\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Zf-mnVVLv7YE"
      },
      "outputs": [],
      "source": [
        "def _export_quant_conv_weights_to_vhdl_kernels(fp, layer_name: str, kernels: np.ndarray):\n",
        "    kernel_h = kernels.shape[0]\n",
        "    kernel_w = kernels.shape[1]\n",
        "    num_c_in = kernels.shape[2]\n",
        "    num_c_out = kernels.shape[3]\n",
        "\n",
        "    total_size = kernel_h * kernel_w * num_c_in * num_c_out\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_HEIGHT : integer := {kernel_h};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_WIDTH : integer := {kernel_w};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_C_IN : integer := {num_c_in};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_C_OUT : integer := {num_c_out};\\n\")\n",
        "\n",
        "    # write weights\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS : std_logic_vector(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(kernels.flatten()):\n",
        "        repr_el = 0 if el == -1 else 1  # binary representation of el\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 16 == 0 else ''}\"\n",
        "                 f\"\\'{repr_el}\\'\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_conv_weights_to_vhdl_kernels(fp, layer_name: str, kernels: np.ndarray):\n",
        "    kernel_h = kernels.shape[0]\n",
        "    kernel_w = kernels.shape[1]\n",
        "    num_c_in = kernels.shape[2]\n",
        "    num_c_out = kernels.shape[3]\n",
        "\n",
        "    total_size = kernel_h * kernel_w * num_c_in * num_c_out\n",
        "\n",
        "    # write sizes\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_HEIGHT : integer := {kernel_h};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_WIDTH : integer := {kernel_w};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_C_IN : integer := {num_c_in};\\n\")\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS_C_OUT : integer := {num_c_out};\\n\")\n",
        "\n",
        "    # write weights\n",
        "    fp.write(f\"\\tconstant {layer_name.upper()}_KERNELS : t_weight_array(0 to {total_size - 1}) := (\")\n",
        "    for idx, el in enumerate(kernels.flatten()):\n",
        "        el_2sc = (2 ** 32 + el) if el < 0 else el  # 2's compl\n",
        "        fp.write(f\"{', ' if idx != 0 else str()}\"\n",
        "                 f\"{f'{chr(10)}{chr(9)}{chr(9)}' if idx % 4 == 0 else ''}\"\n",
        "                 f\"\\\"{el_2sc:032b}\\\"\")\n",
        "    fp.write(\"\\n\\t);\\n\\n\")\n",
        "\n",
        "\n",
        "def _export_quant_conv_weights_to_vhdl_biases(fp, layer_name: str, biases: np.ndarray):\n",
        "    raise NotImplementedError(\"Quantized convolutional layers with biases are not supported.\")\n",
        "\n",
        "\n",
        "def _export_conv_weights_to_vhdl_biases(fp, layer_name: str, biases: np.ndarray):\n",
        "    raise NotImplementedError(\"Convolutional layers with biases are not supported.\")\n",
        "\n",
        "\n",
        "def _export_conv_weights_to_vhdl(fp, layer_name: str,\n",
        "                                 layer_data: Dict,\n",
        "                                 quantized: bool = False):\n",
        "\n",
        "    # set functions according to the quantization flag\n",
        "    if quantized:\n",
        "        export_kernels = _export_quant_conv_weights_to_vhdl_kernels\n",
        "        export_biases = _export_quant_conv_weights_to_vhdl_biases\n",
        "    else:\n",
        "        export_kernels = _export_conv_weights_to_vhdl_kernels\n",
        "        export_biases = _export_conv_weights_to_vhdl_biases\n",
        "\n",
        "    if len(layer_data.keys()) == 2:\n",
        "        # with biases\n",
        "        # make sure this is indeed the correct order\n",
        "        kernels = np.array(layer_data['kernels'])\n",
        "        biases = np.array(layer_data['biases'])\n",
        "        _dbg(f\"\\t\\t - weights (shape {kernels.shape})\\n\"\n",
        "             f\"\\t\\t - biases (shape {biases.shape})\")\n",
        "        export_kernels(fp, layer_name, kernels)\n",
        "        export_biases(fp, layer_name, kernels)\n",
        "    elif len(layer_data.keys()) == 1:\n",
        "        # without biases\n",
        "        kernels = np.array(layer_data['kernels'])\n",
        "        _dbg(f\"\\t\\t - weights (shape {kernels.shape})\")\n",
        "        export_kernels(fp, layer_name, kernels)\n",
        "    else:\n",
        "        raise ValueError('Too many weight tensors in this layer.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "qfyE33kHwVc7"
      },
      "outputs": [],
      "source": [
        "def _dispatch_export_weights_layer_specific(fp, layer_name: str,\n",
        "                                            layer_data: Dict,\n",
        "                                            invert_bn_vars: bool = False,\n",
        "                                            inverted_bn_vars_prec: int = 10) -> None:\n",
        "    weightless_layers = ['pool', 'flatten', 'activation']\n",
        "\n",
        "    if 'quant_conv2d' in layer_name:\n",
        "        _dbg(f\"\\t - quantized convolutional layer <{layer_name}>\")\n",
        "        fp.write(f\"\\t--- Layer <{layer_name}>\\n\")\n",
        "        _export_conv_weights_to_vhdl(fp, layer_name, layer_data, quantized=True)\n",
        "    elif 'conv2d' in layer_name:\n",
        "        _dbg(f\"\\t - convolutional layer <{layer_name}>\")\n",
        "        # write layer name\n",
        "        fp.write(f\"\\t--- Layer <{layer_name}>\\n\")\n",
        "        _export_conv_weights_to_vhdl(fp, layer_name, layer_data)\n",
        "    elif 'batch_normalization' in layer_name:\n",
        "        _dbg(f\"\\t - batch normalization layer <{layer_name}>\")\n",
        "        # write layer name\n",
        "        fp.write(f\"\\t--- Layer <{layer_name}>\\n\")\n",
        "        _export_bn_weights_to_vhdl(fp, layer_name, layer_data, invert_bn_vars, inverted_bn_vars_prec)\n",
        "    elif 'quant_dense' in layer_name:\n",
        "        _dbg(f\"\\t - quantized dense layer <{layer_name}>\")\n",
        "        # write layer name\n",
        "        fp.write(f\"\\t--- Layer <{layer_name}>\\n\")\n",
        "        _export_dense_weights_to_vhdl(fp, layer_name, layer_data, quantized=True)\n",
        "    elif 'dense' in layer_name:\n",
        "        _dbg(f\"\\t - dense layer <{layer_name}>\")\n",
        "        # write layer name\n",
        "        fp.write(f\"\\t--- Layer <{layer_name}>\\n\")\n",
        "        _export_dense_weights_to_vhdl(fp, layer_name, layer_data)\n",
        "    elif any([wl in layer_name for wl in weightless_layers]):\n",
        "        # a supported layer that has no weights\n",
        "        _dbg(f\"\\t - ignoring weightless layer <{layer_name}>\")\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError('This layer type is not supported.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "CmmMAC3Td9uF"
      },
      "outputs": [],
      "source": [
        "def export_weights_to_vhdl(model: Dict | str,\n",
        "                           vhdl_out_path: str,\n",
        "                           vhdl_out: str,\n",
        "                           invert_bn_vars: bool = False,\n",
        "                           inverted_bn_vars_prec: int = -10) -> None:\n",
        "    \"\"\"Hardcodes neural net model weights into a `.vhd` file.\n",
        "    Only supports integer weights for now.\n",
        "\n",
        "    Args:\n",
        "    `model` -- object containing the weights. if this is a string,\n",
        "    then it should point to a `.json` file containing the weights\n",
        "    `vhdl_out_path` -- the path to the output `.vhd` file\n",
        "    `vhdl_out` -- the name of the output `.vhd` file\n",
        "    `invert_bn_vars` -- if set, batch normalization layer variances are also\n",
        "    exported inverted, to make it easier for hardware multiplication\n",
        "    (default `False`)\n",
        "    `inverted_bn_vars_prec` -- the fixed decimal precision of the inverted variances\n",
        "    \"\"\"\n",
        "\n",
        "    _dbg(f\"Exporting weights from \"\n",
        "         f\"{model if type(model) == str else 'pre-loaded model'} \"\n",
        "         f\"to {vhdl_out_path}/{vhdl_out}.vhd\")\n",
        "\n",
        "    # load model weights in memory if a file was provided\n",
        "    if type(model) == str:\n",
        "        with open(model, 'r') as fp:\n",
        "            model = load(fp)\n",
        "\n",
        "    # write the .vhd file\n",
        "    full_vhdl_out_path = f'{vhdl_out_path}/{vhdl_out}.vhd'\n",
        "    with open(full_vhdl_out_path, 'w') as fp:\n",
        "\n",
        "        # write vhdl package header\n",
        "        fp.write(f\"library IEEE;\\n\"\n",
        "                 f\"use IEEE.STD_LOGIC_1164.ALL;\\n\\n\"\n",
        "                 f\"package WeightsPack is\\n\"\n",
        "                 f\"\\t-- Weight array type definition\\n\")\n",
        "\n",
        "        # write array type declarations\n",
        "        fp.write(f\"\\ttype t_weight_array is array (integer range <>) of std_logic_vector(31 downto 0);\\n\"\n",
        "                 f\"\\ttype t_quant_weight_array is array (integer range <>) of std_logic;\\n\\n\")\n",
        "\n",
        "        # export the weights of each layer based on the layer type\n",
        "        for layer_name, layer_data in model.items():\n",
        "            _dispatch_export_weights_layer_specific(fp,\n",
        "                                                    layer_name,\n",
        "                                                    layer_data,\n",
        "                                                    invert_bn_vars,\n",
        "                                                    inverted_bn_vars_prec)\n",
        "\n",
        "        # write vhdl package end footer\n",
        "        fp.write(f\"end package WeightsPack;\\n\")\n",
        "\n",
        "    _dbg(\"Weight export complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "6EzpTYpNj9zQ"
      },
      "outputs": [],
      "source": [
        "vhdl_out_path = workdir\n",
        "vhdl_out = 'weights'\n",
        "invert_bn_vars = True\n",
        "inverted_bn_vars_prec = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "tg0Fh36ljzb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ddadaa-5f87-4a00-a210-df988727d5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting weights from ./drive/MyDrive//weights_compensated.json to ./drive/MyDrive//weights.vhd\n",
            "\t - quantized convolutional layer <quant_conv2d_1>\n",
            "\t\t - weights (shape (5, 5, 1, 8))\n",
            "\t - ignoring weightless layer <max_pooling2d_1>\n",
            "\t - batch normalization layer <batch_normalization_1>\n",
            "\t\t - means (shape (8,))\n",
            "\t\t - variances (shape (8,))\n",
            "\t\t - shifting inverted vars 9 times to the left\n",
            "\t - quantized convolutional layer <quant_conv2d_2>\n",
            "\t\t - weights (shape (3, 3, 8, 32))\n",
            "\t - ignoring weightless layer <max_pooling2d_2>\n",
            "\t - batch normalization layer <batch_normalization_2>\n",
            "\t\t - means (shape (32,))\n",
            "\t\t - variances (shape (32,))\n",
            "\t\t - shifting inverted vars 12 times to the left\n",
            "\t - ignoring weightless layer <flatten_1>\n",
            "\t - quantized dense layer <quant_dense_1>\n",
            "\t\t - weights (shape (288, 64))\n",
            "\t - batch normalization layer <batch_normalization_3>\n",
            "\t\t - means (shape (64,))\n",
            "\t\t - variances (shape (64,))\n",
            "\t\t - shifting inverted vars 14 times to the left\n",
            "\t - quantized dense layer <quant_dense_2>\n",
            "\t\t - weights (shape (64, 10))\n",
            "\t - batch normalization layer <batch_normalization_4>\n",
            "\t\t - means (shape (10,))\n",
            "\t\t - variances (shape (10,))\n",
            "\t\t - shifting inverted vars 13 times to the left\n",
            "\t - ignoring weightless layer <activation_1>\n",
            "Weight export complete.\n"
          ]
        }
      ],
      "source": [
        "# export_weights_to_vhdl(lq_int_model_dict, vhdl_out_path, vhdl_out)\n",
        "# export_weights_to_vhdl(f'{workdir}/weights_test.json', vhdl_out_path, vhdl_out)\n",
        "export_weights_to_vhdl(f'{workdir}/weights_compensated.json',\n",
        "                       vhdl_out_path,\n",
        "                       vhdl_out,\n",
        "                       invert_bn_vars,\n",
        "                       inverted_bn_vars_prec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycy0hsSNZB2P"
      },
      "source": [
        "# VHDL inference input file generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGi6lLe4ieNU"
      },
      "source": [
        "## Input image integer quantization\n",
        "\n",
        "Test if ceiling the pixel values significantly changes the input image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kWEtRCdihWV"
      },
      "outputs": [],
      "source": [
        "img = test_x[0]\n",
        "quant_img = np.empty_like(img, dtype=np.int32)\n",
        "# quan_bin_img = np.empty_like(img, dtype=np.int8)\n",
        "np.ceil(img, out=quant_img, casting='unsafe')\n",
        "quant_bin_img = (quant_img >= 0)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3)\n",
        "\n",
        "# unquantized\n",
        "axs[0].imshow(img, cmap='gray')\n",
        "axs[0].set_title('Unquantized')\n",
        "\n",
        "# quantized\n",
        "axs[1].imshow(quant_img, cmap='gray')\n",
        "axs[1].set_title('Quantized')\n",
        "\n",
        "# quantized binary\n",
        "axs[2].imshow(quant_bin_img, cmap='gray')\n",
        "axs[2].set_title('Quantized binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELmr_pFQjS9D"
      },
      "source": [
        "## Extract the  image into a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK5aKnxKjeiq"
      },
      "outputs": [],
      "source": [
        "def _export_mnist_example_row_to_vhdl(fp,\n",
        "                                      row: np.ndarray,\n",
        "                                      last: bool = False) -> None:\n",
        "    row = np.squeeze(row, 0)\n",
        "    str_row = ', '.join(f\"\\\"{convert_to_2s_complement(el)}\\\"\" for el in row)\n",
        "    fp.write(f\"\\t\\t{str_row}{'' if last else ','}\\n\")\n",
        "\n",
        "\n",
        "def _export_mnist_example_row_to_vhdl_binary(fp,\n",
        "                                             row: np.ndarray,\n",
        "                                             last: bool = False) -> None:\n",
        "    row = np.squeeze(row, 0)\n",
        "    binary_row = row >= 0\n",
        "    str_binary_row = ', '.join(f\"\\'{int(el)}\\'\" for el in binary_row)\n",
        "    fp.write(f\"\\t\\t{str_binary_row}{'' if last else ','}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4PtqaUtZIg0"
      },
      "outputs": [],
      "source": [
        "def export_mnist_example_to_vhdl(ex: np.ndarray,\n",
        "                           vhdl_out_path: str,\n",
        "                           vhdl_out: str,\n",
        "                           binary: bool = False) -> None:\n",
        "    \"\"\"Hardcodes an example from the MNIST dataset into a `.vhd` file.\n",
        "    Quantizes the values to integers.\n",
        "\n",
        "    Args:\n",
        "    `ex` -- array representing the input example\n",
        "    `vhdl_out_path` -- the path to the output `.vhd` file\n",
        "    `vhdl_out` -- the name of the output `.vhd` file\n",
        "    `binary` -- if true, export the example as binary (default `False`)\n",
        "    \"\"\"\n",
        "\n",
        "    MNIST_W = 28\n",
        "    MNIST_H = 28\n",
        "\n",
        "    _dbg(f\"Exporting example \"\n",
        "         f\"to {vhdl_out_path}/{vhdl_out}.vhd\")\n",
        "\n",
        "    if binary:\n",
        "        array_el_type = \"std_logic\"\n",
        "        export_row = _export_mnist_example_row_to_vhdl_binary\n",
        "    else:\n",
        "        array_el_type = \"std_logic_vector(31 downto 0)\"\n",
        "        export_row = _export_mnist_example_row_to_vhdl\n",
        "\n",
        "    # squeeze the channel dimension, since MNIST has only one channel\n",
        "    ex = np.squeeze(ex, -1)\n",
        "\n",
        "     # write the .vhd file\n",
        "    full_vhdl_out_path = f'{vhdl_out_path}/{vhdl_out}.vhd'\n",
        "    with open(full_vhdl_out_path, 'w') as fp:\n",
        "\n",
        "        # write vhdl package header\n",
        "        fp.write(f\"library IEEE;\\n\"\n",
        "                 f\"use IEEE.STD_LOGIC_1164.ALL;\\n\\n\"\n",
        "                 f\"package InputExamplePack is\\n\"\n",
        "                 f\"\\t-- Input array type definition\\n\")\n",
        "\n",
        "        # write array type declarations\n",
        "        fp.write(f\"\\ttype t_input_array is array (0 to ({MNIST_H} * {MNIST_W} - 1)) of {array_el_type};\\n\")\n",
        "\n",
        "        # quantize input image\n",
        "        quant_ex = np.empty_like(ex, dtype=np.int32)\n",
        "        np.ceil(ex, out=quant_ex, casting='unsafe')\n",
        "\n",
        "        # write the constant array declaration\n",
        "        fp.write(f\"\\tconstant INPUT : t_input_array := (\\n\")\n",
        "\n",
        "        # export the input example\n",
        "        for idx, row in enumerate(np.split(quant_ex, MNIST_H)):\n",
        "            export_row(fp, row, last=(idx == MNIST_W - 1))\n",
        "\n",
        "        fp.write(\"\\t);\\n\")\n",
        "\n",
        "        # write vhdl package end footer\n",
        "        fp.write(f\"end package InputExamplePack;\\n\")\n",
        "\n",
        "    _dbg(\"Example export complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbMYlwBeZ_S5"
      },
      "outputs": [],
      "source": [
        "example_vhdl_out_path = workdir\n",
        "example_vhdl_out = 'example_test'\n",
        "example_vhdl_out_binary = 'example_test_binary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5epuTYX-Z50f"
      },
      "outputs": [],
      "source": [
        "export_mnist_example_to_vhdl(test_x[0], example_vhdl_out_path, example_vhdl_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25xvCwEoDoM3"
      },
      "outputs": [],
      "source": [
        "export_mnist_example_to_vhdl(test_x[0], example_vhdl_out_path, example_vhdl_out_binary, binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDFnVp6nATYM"
      },
      "source": [
        "# Playground\n",
        "\n",
        "Fuck around here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "713E0k9YKRbI"
      },
      "outputs": [],
      "source": [
        "# for layer in model.layers:\n",
        "    # print(layer.get_config(), layer.get_weights())\n",
        "\n",
        "with lq.context.quantized_scope(True):\n",
        "  for layer in model.layers:\n",
        "\n",
        "    # maybe take the config dict and remove some keys; only keep the name of the layer, maybe the kernel size and the weights\n",
        "    # print(layer.get_config(), layer.get_weights())\n",
        "    print(layer.get_weights())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ddhSdu2zlDXj",
        "zu9jpxcxldAy",
        "7uo0boAG1gmW",
        "JgQYMSip39ZZ",
        "DuXmlSSvTsor",
        "sK7VP9f93qTy",
        "hSCPaHQeTvjC",
        "VPHwdLk7MjvW",
        "3eQXdwPNZOR1",
        "ZQnhZUj-T2ly",
        "cdx8sZ8upj63",
        "7odb7HQdvT9p",
        "X7TGHX8jo-yn",
        "R4uBzywTziqG",
        "dl89oKbqzlJY",
        "oWfQNIBL8ygJ",
        "dmd6O5DHKPPM",
        "wQH1zMyclZI9",
        "ycy0hsSNZB2P",
        "zDFnVp6nATYM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}